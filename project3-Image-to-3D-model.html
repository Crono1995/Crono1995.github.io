<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>AI 3D Model Generator - GitHub.io</title>
    <script src="https://cdn.tailwindcss.com"></script>
    <script src="https://cdnjs.cloudflare.com/ajax/libs/three.js/0.165.0/three.min.js"></script>
    <script src="https://cdn.jsdelivr.net/npm/@tensorflow/tfjs@4.17.0/dist/tf.min.js"></script>
    <script src="https://cdn.jsdelivr.net/npm/three@0.165.0/examples/js/controls/OrbitControls.js"></script>
    <script src="https://unpkg.com/lucide@latest"></script>
    <style>
        /* Custom styles based on the React components' appearance */
        .text-gradient {
            background-image: linear-gradient(45deg, #10b981, #3b82f6);
            -webkit-background-clip: text;
            -webkit-text-fill-color: transparent;
        }
        .gradient-primary {
            background-color: #3b82f6;
            color: white;
            transition: background-color 0.2s;
        }
        .gradient-primary:hover:not(:disabled) {
            background-color: #2563eb;
        }
        .card {
            background-color: white;
            border-radius: 0.5rem;
            box-shadow: 0 4px 6px -1px rgba(0, 0, 0, 0.1), 0 2px 4px -2px rgba(0, 0, 0, 0.1);
        }
        .bg-background { background-color: #f3f4f6; }
        .min-h-screen { min-height: 100vh; }
        .loader-spin { animation: spin 1s linear infinite; }
        @keyframes spin { 100% { transform: rotate(360deg); } }
        /* Toast Notification Styling */
        #toast-container {
            position: fixed;
            top: 1rem;
            right: 1rem;
            z-index: 1000;
        }
        .toast {
            margin-top: 0.5rem;
            padding: 1rem;
            border-radius: 0.375rem;
            color: white;
            box-shadow: 0 10px 15px -3px rgba(0, 0, 0, 0.1), 0 4px 6px -4px rgba(0, 0, 0, 0.1);
            transition: opacity 0.3s ease-out;
            opacity: 1;
        }
        .toast.destructive { background-color: #ef4444; }
        .toast.success { background-color: #10b981; }
        .toast.info { background-color: #3b82f6; }
    </style>
</head>
<body class="bg-background">
    <div id="toast-container"></div>
    <div class="min-h-screen py-8 px-4">
        <div class="max-w-7xl mx-auto">
            <div class="text-center mb-12">
                <div class="flex items-center justify-center gap-3 mb-4">
                    <i data-lucide="box" class="w-10 h-10 text-[#3b82f6]"></i>
                    <h1 class="text-5xl font-bold text-gradient">AI 3D Model Generator</h1>
                </div>
                <p class="text-gray-500 text-lg">
                    Transform 2D images into 3D models using AI â€¢ 100% Client-Side â€¢ No Server Required
                </p>
            </div>

            <div class="grid lg:grid-cols-2 gap-6 mb-8">
                <div class="card p-6 space-y-6">
                    <div>
                        <h2 class="text-xl font-semibold mb-4 flex items-center gap-2">
                            <span class="text-[#3b82f6]">1.</span> Upload Image
                        </h2>
                        <div class="border-2 border-dashed border-gray-300 rounded-lg p-6 text-center hover:border-[#3b82f6] transition cursor-pointer">
                            <input type="file" id="image-upload-input" accept="image/*" class="hidden">
                            <label for="image-upload-input" id="upload-label" class="block cursor-pointer">
                                <i data-lucide="image" class="w-8 h-8 mx-auto text-gray-400 mb-2"></i>
                                <p class="text-sm text-gray-600">Click to upload or drag and drop</p>
                                <p class="text-xs text-gray-500">PNG, JPG, up to 10MB</p>
                            </label>
                            <img id="selected-image-preview" class="mt-4 hidden max-h-64 object-contain mx-auto" src="" alt="Selected Image">
                        </div>
                    </div>

                    <div>
                        <h2 class="text-xl font-semibold mb-4 flex items-center gap-2">
                            <span class="text-[#3b82f6]">2.</span> Depth Map
                        </h2>
                        <div id="depth-map-container" class="border border-gray-200 rounded-lg bg-gray-100 flex items-center justify-center h-64 overflow-hidden">
                            <p id="depth-map-placeholder" class="text-gray-500">Depth Map will appear here</p>
                            <canvas id="depth-map-canvas" class="hidden max-w-full max-h-full"></canvas>
                        </div>
                    </div>
                </div>

                <div class="card p-6 space-y-6">
                    <div>
                        <h2 class="text-xl font-semibold mb-4 flex items-center gap-2">
                            <span class="text-[#3b82f6]">3.</span> 3D Model Viewer
                        </h2>
                        <div id="viewer-3d-container" class="border border-gray-200 rounded-lg bg-gray-100 flex items-center justify-center h-64 relative">
                            <div id="threejs-container" class="w-full h-full"></div>
                            <p id="viewer-placeholder" class="text-gray-500 absolute top-1/2 left-1/2 -translate-x-1/2 -translate-y-1/2">3D Model will appear here</p>
                        </div>
                    </div>

                    <div class="space-y-3">
                        <button id="generate-button" disabled class="w-full h-12 text-base gradient-primary transition-opacity flex items-center justify-center rounded-lg disabled:opacity-50">
                            <i data-lucide="box" class="w-5 h-5 mr-2"></i>
                            <span id="generate-text">Generate 3D Model</span>
                        </button>

                        <button id="export-button" disabled class="w-full h-12 text-base border border-gray-300 text-gray-700 hover:bg-gray-100 transition flex items-center justify-center rounded-lg disabled:opacity-50">
                            <i data-lucide="download" class="w-5 h-5 mr-2"></i>
                            Download OBJ
                        </button>
                    </div>
                </div>
            </div>

            <div class="grid md:grid-cols-3 gap-4">
                <div class="card p-4 bg-gray-50 border border-gray-200">
                    <h3 class="font-semibold text-[#3b82f6] mb-2">ðŸ”’ Privacy First</h3>
                    <p class="text-sm text-gray-500">
                        All processing happens locally in your browser. No data is uploaded to any server.
                    </p>
                </div>
                <div class="card p-4 bg-gray-50 border border-gray-200">
                    <h3 class="font-semibold text-[#3b82f6] mb-2">âš¡ WebGL Accelerated</h3>
                    <p class="text-sm text-gray-500">
                        Powered by TensorFlow.js with WebGL backend for fast performance.
                    </p>
                </div>
                <div class="card p-4 bg-gray-50 border border-gray-200">
                    <h3 class="font-semibold text-[#3b82f6] mb-2">ðŸ“¦ Export Ready</h3>
                    <p class="text-sm text-gray-500">
                        Export to OBJ format compatible with Blender, Unity, and other 3D tools.
                    </p>
                </div>
            </div>
        </div>
    </div>

    <script>
        // Initialize Lucide Icons
        lucide.createIcons();

        // --- GLOBAL STATE ---
        let selectedImageBase64 = null;
        let depthMapImageData = null;
        let generatedMesh = null;
        let isProcessing = false;

        // --- TOAST NOTIFICATION SYSTEM (Replacement for useToast) ---
        const toastContainer = document.getElementById('toast-container');
        function showToast({ title, description, variant = 'info' }) {
            const toastDiv = document.createElement('div');
            toastDiv.className = `toast ${variant} max-w-sm`;
            toastDiv.innerHTML = `
                <div class="font-bold">${title}</div>
                <p class="text-sm">${description}</p>
            `;
            toastContainer.appendChild(toastDiv);

            setTimeout(() => {
                toastDiv.style.opacity = '0';
                setTimeout(() => toastDiv.remove(), 300);
            }, 5000);
        }

        // --- 1. IMAGE UPLOAD FIX (Vanilla JS) ---
        const imageInput = document.getElementById('image-upload-input');
        const imagePreview = document.getElementById('selected-image-preview');
        const uploadLabel = document.getElementById('upload-label');
        const generateButton = document.getElementById('generate-button');
        const exportButton = document.getElementById('export-button');

        imageInput.addEventListener('change', (event) => {
            const file = event.target.files[0];
            if (file) {
                const reader = new FileReader();
                reader.onload = (e) => {
                    selectedImageBase64 = e.target.result;
                    imagePreview.src = selectedImageBase64;
                    imagePreview.classList.remove('hidden');
                    uploadLabel.classList.add('hidden');
                    depthMapImageData = null;
                    generatedMesh = null;
                    clearDepthMap();
                    clear3DViewer();
                    generateButton.disabled = false;
                    exportButton.disabled = true;
                };
                reader.readAsDataURL(file);
            }
        });

        // --- 2. DEPTH ESTIMATION CLASS (Simplified, uses MiDaS model) ---
        class DepthEstimator {
            constructor() {
                this.model = null;
                this.modelName = 'midas/model'; // Using a robust model for client-side
                this.inputSize = 256; // Standard input size for many MiDaS variants
            }

            async loadModel() {
                if (!this.model) {
                    showToast({ title: "Loading AI Model", description: "Downloading depth estimation model (first time may take a moment)..." });
                    this.model = await tf.loadGraphModel(`https://tfhub.dev/google/tfjs-model/${this.modelName}/1/default/1`, { fromTFHub: true });
                    showToast({ title: "Model Ready", description: "AI model loaded successfully.", variant: 'success' });
                }
            }

            async estimateDepth(image) {
                await this.loadModel();

                // 1. Preprocess: Resize and Normalize
                const tfImage = tf.browser.fromPixels(image);
                const resizedImage = tf.image.resizeBilinear(tfImage, [this.inputSize, this.inputSize]);
                const normalized = resizedImage.div(255.0);
                const batched = normalized.expandDims(0);

                // 2. Predict Depth Map
                const outputTensor = await this.model.predict(batched);
                let depthMapTensor = outputTensor;

                // 3. Postprocess: Rescale to original image size and convert to ImageData
                // The MiDaS model output needs to be normalized to 0-1 and then scaled.
                const min = depthMapTensor.min();
                const max = depthMapTensor.max();
                // Invert depth map: White (1.0) is close, Black (0.0) is far.
                const invertedNormalizedDepth = tf.sub(1.0, depthMapTensor.sub(min).div(max.sub(min))).squeeze(); 
                
                // Resize to original image dimensions for accurate mesh generation
                const resizedDepth = tf.image.resizeBilinear(invertedNormalizedDepth.expandDims(2), [image.height, image.width]);
                const scaledDepth = resizedDepth.mul(255).cast('int32').clipByValue(0, 255);
                
                const depthData = await scaledDepth.data();
                const depthMapData = new Uint8ClampedArray(image.width * image.height * 4);

                // Convert to RGBA ImageData for display and mesh generation
                for (let i = 0; i < depthData.length; i++) {
                    const depthValue = depthData[i];
                    const index = i * 4;
                    depthMapData[index] = depthValue;     // R
                    depthMapData[index + 1] = depthValue; // G
                    depthMapData[index + 2] = depthValue; // B
                    depthMapData[index + 3] = 255;        // A (fully opaque)
                }

                tfImage.dispose();
                resizedImage.dispose();
                normalized.dispose();
                batched.dispose();
                outputTensor.dispose();
                invertedNormalizedDepth.dispose();
                resizedDepth.dispose();
                scaledDepth.dispose();

                return new ImageData(depthMapData, image.width, image.height);
            }
        }
        
        // --- DEPTH MAP VIEWER (Display) ---
        const depthMapCanvas = document.getElementById('depth-map-canvas');
        const depthMapPlaceholder = document.getElementById('depth-map-placeholder');
        
        function clearDepthMap() {
            depthMapCanvas.classList.add('hidden');
            depthMapPlaceholder.classList.remove('hidden');
            depthMapCanvas.width = 0;
            depthMapCanvas.height = 0;
        }

        function displayDepthMap(imageData) {
            depthMapCanvas.width = imageData.width;
            depthMapCanvas.height = imageData.height;
            const ctx = depthMapCanvas.getContext('2d');
            ctx.putImageData(imageData, 0, 0);
            
            // Scale canvas to fit container visually
            depthMapCanvas.style.width = 'auto';
            depthMapCanvas.style.height = '100%';
            depthMapCanvas.classList.remove('hidden');
            depthMapPlaceholder.classList.add('hidden');
        }

        // --- 3. MESH GENERATION FIX (The Core Fix) ---
        class MeshGenerator {
            // FIX: This implementation corrects the vertex and face generation 
            // from the 2D depth map to a 3D mesh.
            generateMeshFromDepth(imageData) {
                const { data, width, height } = imageData;
                const geometry = new THREE.BufferGeometry();
                
                const vertices = [];
                const uvs = [];
                const indices = [];

                const depthScale = 0.5; // Controls the Z-depth exaggeration (tweakable)
                const aspectRatio = width / height;

                // 1. Create Vertices and UVs
                for (let y = 0; y < height; y++) {
                    for (let x = 0; x < width; x++) {
                        // Depth is stored in the R, G, and B channels (all the same for grayscale)
                        const i = (y * width + x) * 4;
                        // Map depth from 0-255 to a normalized depth value 0.0 - 1.0
                        const normalizedDepth = data[i] / 255.0; 
                        
                        // FIX: Normalize X, Y coordinates to be centered around (0, 0)
                        // X: -0.5 to 0.5 (scaled by aspect ratio to maintain square pixels)
                        const vx = (x / width - 0.5) * aspectRatio; 
                        // Y: -0.5 to 0.5 (Y is usually inverted in graphics, hence 0.5 - y/height)
                        const vy = (0.5 - y / height); 
                        // Z: Scale depth to control extrusion. Near (1.0) is front, Far (0.0) is back.
                        const vz = normalizedDepth * depthScale; 
                        
                        vertices.push(vx, vy, vz);
                        
                        // UV coordinates for texture mapping (0.0 - 1.0)
                        uvs.push(x / (width - 1), 1 - y / (height - 1)); // 1-y to flip Y for texture
                    }
                }

                // 2. Create Faces (Indices) - Quad to two Triangles
                for (let y = 0; y < height - 1; y++) {
                    for (let x = 0; x < width - 1; x++) {
                        const i = y * width + x;
                        const i_right = y * width + x + 1;
                        const i_down = (y + 1) * width + x;
                        const i_diag = (y + 1) * width + x + 1;

                        // Triangle 1 (Top-Left, Bottom-Left, Top-Right)
                        indices.push(i, i_down, i_right);

                        // Triangle 2 (Top-Right, Bottom-Left, Bottom-Right)
                        indices.push(i_right, i_down, i_diag);
                    }
                }

                geometry.setIndex(indices);
                geometry.setAttribute('position', new THREE.Float32BufferAttribute(vertices, 3));
                geometry.setAttribute('uv', new THREE.Float32BufferAttribute(uvs, 2));

                geometry.computeVertexNormals();
                
                return geometry;
            }

            exportToOBJ(geometry) {
                const vertices = geometry.getAttribute('position').array;
                const indices = geometry.getIndex().array;
                
                let obj = '# OBJ file generated from Depth Map\n';
                
                // Write Vertices
                for (let i = 0; i < vertices.length; i += 3) {
                    obj += `v ${vertices[i]} ${vertices[i + 1]} ${vertices[i + 2]}\n`;
                }

                // Write Faces (using 1-based indexing for OBJ)
                for (let i = 0; i < indices.length; i += 3) {
                    // +1 because OBJ is 1-indexed
                    const v1 = indices[i] + 1;
                    const v2 = indices[i + 1] + 1;
                    const v3 = indices[i + 2] + 1;
                    obj += `f ${v1} ${v2} ${v3}\n`;
                }
                
                return obj;
            }

            downloadOBJ(content) {
                const blob = new Blob([content], { type: 'text/plain' });
                const url = URL.createObjectURL(blob);
                const a = document.createElement('a');
                a.href = url;
                a.download = '3d_model_from_depth.obj';
                document.body.appendChild(a);
                a.click();
                document.body.removeChild(a);
                URL.revokeObjectURL(url);
            }
        }

        // --- 4. 3D VIEWER (Three.js) ---
        let scene, camera, renderer, controls, meshObject, ambientLight, directionalLight;
        const viewerContainer = document.getElementById('threejs-container');
        const viewerPlaceholder = document.getElementById('viewer-placeholder');

        function init3DViewer() {
            if (scene) return; // Already initialized

            scene = new THREE.Scene();
            scene.background = new THREE.Color(0xf0f0f0); // Light background

            // Camera setup
            camera = new THREE.PerspectiveCamera(75, viewerContainer.clientWidth / viewerContainer.clientHeight, 0.1, 1000);
            camera.position.z = 2;

            // Renderer setup
            renderer = new THREE.WebGLRenderer({ antialias: true });
            renderer.setSize(viewerContainer.clientWidth, viewerContainer.clientHeight);
            viewerContainer.appendChild(renderer.domElement);

            // Lighting
            ambientLight = new THREE.AmbientLight(0x404040, 5); // soft white light
            scene.add(ambientLight);

            directionalLight = new THREE.DirectionalLight(0xffffff, 3);
            directionalLight.position.set(1, 1, 1).normalize();
            scene.add(directionalLight);

            // Controls
            controls = new THREE.OrbitControls(camera, renderer.domElement);
            controls.enableDamping = true;
            controls.dampingFactor = 0.25;
            controls.screenSpacePanning = false;
            controls.minDistance = 0.5;
            controls.maxDistance = 5;

            // Resize listener
            window.addEventListener('resize', onWindowResize, false);

            animate();
        }

        function onWindowResize() {
            if (camera && renderer) {
                camera.aspect = viewerContainer.clientWidth / viewerContainer.clientHeight;
                camera.updateProjectionMatrix();
                renderer.setSize(viewerContainer.clientWidth, viewerContainer.clientHeight);
            }
        }
        
        function animate() {
            requestAnimationFrame(animate);
            if (controls) controls.update();
            if (renderer && scene && camera) renderer.render(scene, camera);
        }

        function clear3DViewer() {
            if (meshObject) {
                scene.remove(meshObject);
                meshObject.geometry.dispose();
                meshObject.material.dispose();
                meshObject = null;
            }
            viewerPlaceholder.classList.remove('hidden');
        }

        function displayMesh(geometry, textureImage) {
            clear3DViewer();
            
            // FIX: Load the original image as a texture
            const texture = new THREE.Texture(textureImage);
            texture.needsUpdate = true;

            const material = new THREE.MeshPhysicalMaterial({ 
                map: texture, 
                side: THREE.DoubleSide,
                roughness: 0.8,
                metalness: 0.1,
            });

            meshObject = new THREE.Mesh(geometry, material);
            scene.add(meshObject);
            viewerPlaceholder.classList.add('hidden');
            
            // Fit model to view
            const box = new THREE.Box3().setFromObject(meshObject);
            const size = box.getSize(new THREE.Vector3());
            const center = box.getCenter(new THREE.Vector3());

            meshObject.position.sub(center); // Center the mesh
            controls.target.copy(meshObject.position);

            const maxDim = Math.max(size.x, size.y, size.z);
            const fitFactor = 2; 
            camera.position.copy(center);
            camera.position.z = maxDim * fitFactor / (2 * Math.tan(camera.fov * Math.PI / 360));
            camera.position.y = maxDim * 0.5; // Lift up slightly
            camera.updateProjectionMatrix();
            controls.update();

        }
        
        // --- MAIN APPLICATION LOGIC (Handle Buttons) ---
        const depthEstimator = new DepthEstimator();
        const meshGenerator = new MeshGenerator();

        generateButton.addEventListener('click', async () => {
            if (!selectedImageBase64 || isProcessing) return;

            isProcessing = true;
            generateButton.disabled = true;
            generateButton.innerHTML = `<i data-lucide="loader-2" class="w-5 h-5 mr-2 loader-spin"></i> Processing...`;
            lucide.createIcons();
            exportButton.disabled = true;

            try {
                // Load image
                const img = new Image();
                img.src = selectedImageBase64;
                await new Promise((resolve) => { img.onload = resolve; });

                // 1. Estimate Depth
                showToast({ title: "Processing image", description: "Estimating depth map..." });
                const estimatedDepth = await depthEstimator.estimateDepth(img);
                depthMapImageData = estimatedDepth;
                displayDepthMap(estimatedDepth);

                // 2. Generate Mesh
                showToast({ title: "Generating 3D model", description: "Creating mesh from depth data..." });
                const generated = meshGenerator.generateMeshFromDepth(estimatedDepth);
                generatedMesh = generated;
                displayMesh(generated, img); // Pass original image for texture

                showToast({ title: "Success!", description: "3D model generated successfully", variant: 'success' });
                exportButton.disabled = false;

            } catch (error) {
                console.error('Generation error:', error);
                showToast({ 
                    title: "Generation failed", 
                    description: error.message || "An unknown error occurred", 
                    variant: 'destructive' 
                });
            } finally {
                isProcessing = false;
                generateButton.disabled = !selectedImageBase64;
                generateButton.innerHTML = `<i data-lucide="box" class="w-5 h-5 mr-2"></i> <span id="generate-text">Generate 3D Model</span>`;
                lucide.createIcons();
            }
        });

        exportButton.addEventListener('click', () => {
            if (!generatedMesh) {
                showToast({ title: "No model to export", description: "Please generate a 3D model first", variant: 'destructive' });
                return;
            }
            
            try {
                const objContent = meshGenerator.exportToOBJ(generatedMesh);
                meshGenerator.downloadOBJ(objContent);
                showToast({ title: "Export successful", description: "OBJ file downloaded", variant: 'success' });
            } catch (error) {
                showToast({ title: "Export failed", description: "Failed to export the model", variant: 'destructive' });
            }
        });
        
        // --- Initialization on load ---
        document.addEventListener('DOMContentLoaded', () => {
            // Wait for 3D viewer container to be available before init
            init3DViewer(); 
            // Ensures icons are rendered
            lucide.createIcons(); 
        });

    </script>
</body>
</html>
