<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>AI 3D Model Generator (Client-Side)</title>
    <script src="https://cdn.tailwindcss.com"></script>
    <style>
        /* Custom styles to mimic the original app's look */
        .bg-background { background-color: #0d1117; } /* Dark background */
        .card { background-color: #161b22; border-color: #30363d; } /* Dark card background */
        .text-primary { color: #58a6ff; } /* Blue primary color */
        .gradient-primary { background: linear-gradient(to right, #58a6ff, #89c4f4); color: white; }
        .text-gradient { background: linear-gradient(45deg, #58a6ff, #89c4f4); -webkit-background-clip: text; -webkit-text-fill-color: transparent; }
        .text-muted-foreground { color: #8b949e; }
        #viewer3d-container { height: 400px; border-radius: 0.5rem; overflow: hidden; }
        #depth-map-container { height: 400px; background-color: #010409; border-radius: 0.5rem; display: flex; align-items: center; justify-content: center; color: #8b949e; font-style: italic; }
        #loading-spinner { border-width: 4px; border-style: solid; border-color: rgba(255, 255, 255, 0.3); border-top-color: #58a6ff; border-radius: 50%; width: 24px; height: 24px; animation: spin 1s linear infinite; }
        @keyframes spin { 0% { transform: rotate(0deg); } 100% { transform: rotate(360deg); } }
    </style>
    <script src="https://cdn.jsdelivr.net/npm/@tensorflow/tfjs@4.17.0/dist/tf.min.js"></script>
    <script src="https://cdn.jsdelivr.net/npm/@pixiu-tech/tfjs-midas@1.0.0/dist/midas.min.js"></script>
    <script src="https://cdnjs.cloudflare.com/ajax/libs/three.js/r128/three.min.js"></script>
</head>
<body class="bg-background text-white min-h-screen">
    <div class="py-8 px-4 max-w-7xl mx-auto">
        <div class="text-center mb-12">
            <div class="flex items-center justify-center gap-3 mb-4">
                <div class="w-10 h-10 text-primary border-2 border-primary flex items-center justify-center">üì¶</div>
                <h1 class="text-5xl font-bold text-gradient">AI 3D Model Generator</h1>
            </div>
            <p class="text-muted-foreground text-lg">
                Transform 2D images into 3D models using **TRELLIS 3D AI** ‚Ä¢ 100% Client-Side ‚Ä¢ No Server Required
            </p>
        </div>

        <div class="grid lg:grid-cols-2 gap-6 mb-8">
            <div id="left-card" class="p-6 space-y-6 card border">
                <div>
                    <h2 class="text-xl font-semibold mb-4 flex items-center gap-2">
                        <span class="text-primary">1.</span> Upload Image
                    </h2>
                    <div class="border-2 border-dashed border-gray-600 p-4 rounded-lg flex flex-col items-center justify-center h-64">
                        <input type="file" id="file-upload" accept="image/*" class="hidden" onchange="handleImageSelect(event)">
                        <label for="file-upload" id="upload-label" class="cursor-pointer text-primary hover:text-white transition">Click to upload an image</label>
                        <img id="image-preview" src="" alt="Selected Image" class="hidden max-h-full max-w-full object-contain mt-2 rounded-lg">
                    </div>
                </div>

                <div>
                    <h2 class="text-xl font-semibold mb-4 flex items-center gap-2">
                        <span class="text-primary">2.</span> Depth Map
                    </h2>
                    <div id="depth-map-container">
                        Depth map will appear here after generation.
                    </div>
                </div>
            </div>

            <div id="right-card" class="p-6 space-y-6 card border">
                <div>
                    <h2 class="text-xl font-semibold mb-4 flex items-center gap-2">
                        <span class="text-primary">3.</span> 3D Model Viewer
                    </h2>
                    <div id="viewer3d-container">
                        </div>
                </div>

                <div class="space-y-3">
                    <button id="generate-btn" onclick="handleGenerate()" disabled
                        class="w-full h-12 text-base transition-opacity rounded-lg disabled:opacity-50 flex items-center justify-center font-semibold gradient-primary hover:opacity-90">
                        <div id="loading-spinner" class="hidden mr-2"></div>
                        <span id="generate-text">üì¶ Generate 3D Model</span>
                    </button>

                    <button id="export-btn" onclick="handleExport()" disabled
                        class="w-full h-12 text-base rounded-lg border border-primary/30 hover:bg-primary/10 transition-colors bg-transparent text-white font-semibold flex items-center justify-center disabled:opacity-50">
                        <span class="mr-2">‚¨áÔ∏è</span> Download OBJ
                    </button>
                </div>
            </div>
        </div>

        <div class="grid md:grid-cols-3 gap-4">
            <div class="p-4 bg-card/50 border card border-primary/20 rounded-lg">
                <h3 class="font-semibold text-primary mb-2">üîí Privacy First</h3>
                <p class="text-sm text-muted-foreground">
                    All processing happens locally in your browser. No data is uploaded to any server.
                </p>
            </div>
            <div class="p-4 bg-card/50 border card border-primary/20 rounded-lg">
                <h3 class="font-semibold text-primary mb-2">‚ö° WebGL Accelerated</h3>
                <p class="text-sm text-muted-foreground">
                    Powered by **TensorFlow.js** (our TRELLIS 3D AI implementation) with WebGL backend for fast performance.
                </p>
            </div>
            <div class="p-4 bg-card/50 border card border-primary/20 rounded-lg">
                <h3 class="font-semibold text-primary mb-2">üì¶ Export Ready</h3>
                <p class="text-sm text-muted-foreground">
                    Export to OBJ format compatible with Blender, Unity, and other 3D tools.
                </p>
            </div>
        </div>
    </div>

    <script>
        // Global variables for application state
        let selectedImageBase64 = null;
        let currentMesh = null;
        let isProcessing = false;
        let depthModel = null; // MiDaS model instance

        // --- Utility Functions (Toast, 3D Viewer Setup) ---

        /** Simple Toast/Notification function (replaces useToast hook) */
        function showToast(title, description, isDestructive = false) {
            console.log(`[Toast] ${title}: ${description}`);
            const toastElement = document.createElement('div');
            // FIX: Ensure no unexpected tokens in template literal
            toastElement.className = \`fixed top-4 right-4 p-4 rounded-lg shadow-lg z-50 text-white \${isDestructive ? 'bg-red-600' : 'bg-green-600'}\`;
            toastElement.innerHTML = \`<strong>\${title}</strong>: \${description}\`;
            document.body.appendChild(toastElement);

            setTimeout(() => {
                toastElement.remove();
            }, 3000);
        }

        /** Initialize the THREE.js 3D Viewer */
        let scene, camera, renderer, meshGroup;
        function initViewer3D() {
            const container = document.getElementById('viewer3d-container');
            if (!container) return; // Safety check
            
            const width = container.clientWidth;
            const height = container.clientHeight;

            // Scene setup
            scene = new THREE.Scene();
            scene.background = new THREE.Color(0x161b22);

            // Camera setup
            camera = new THREE.PerspectiveCamera(75, width / height, 0.1, 1000);
            camera.position.z = 3;

            // Renderer setup
            renderer = new THREE.WebGLRenderer({ antialias: true });
            renderer.setSize(width, height);
            container.appendChild(renderer.domElement);

            // Lighting
            scene.add(new THREE.AmbientLight(0xffffff, 0.5));
            const directionalLight = new THREE.DirectionalLight(0xffffff, 0.8);
            directionalLight.position.set(1, 1, 1);
            scene.add(directionalLight);

            // Placeholder Group for the generated mesh
            meshGroup = new THREE.Group();
            scene.add(meshGroup);

            // Add simple orbit controls (Basic rotation implementation)
            let isDragging = false;
            let previousMousePosition = { x: 0, y: 0 };

            container.addEventListener('mousedown', (e) => {
                isDragging = true;
                previousMousePosition = { x: e.clientX, y: e.clientY };
            });

            document.addEventListener('mouseup', () => {
                isDragging = false;
            });

            document.addEventListener('mousemove', (e) => {
                if (!isDragging) return;
                const deltaX = e.clientX - previousMousePosition.x;
                const deltaY = e.clientY - previousMousePosition.y;

                // Adjust rotation speed
                meshGroup.rotation.y += deltaX * 0.005; 
                meshGroup.rotation.x += deltaY * 0.005;

                previousMousePosition = { x: e.clientX, y: e.clientY };
            });
            
            // Handle resizing
            window.addEventListener('resize', () => {
                const newWidth = container.clientWidth;
                const newHeight = container.clientHeight;
                camera.aspect = newWidth / newHeight;
                camera.updateProjectionMatrix();
                renderer.setSize(newWidth, newHeight);
            });

            // Render loop
            function animate() {
                requestAnimationFrame(animate);
                renderer.render(scene, camera);
            }
            animate();
        }

        // --- TRELLIS 3D AI Implementation (Depth Estimation and Mesh Generation) ---

        /**
         * TRELLIS 3D AI: Depth Estimator (Using MiDaS via TensorFlow.js)
         * @param {HTMLImageElement} img - The input image element.
         * @returns {Promise<ImageData>} - The generated depth map as ImageData.
         */
        async function estimateDepth(img) {
            if (!depthModel) {
                showToast("Loading AI Model", "Loading MiDaS depth model (approx 50MB)...", false);
                // Load MiDaS model (Large model, may take time)
                depthModel = await midas.load();
                showToast("AI Model Ready", "Depth estimation model loaded successfully!", false);
            }

            // Estimate depth
            const prediction = await depthModel.estimateDepth(img, {
                inputResolution: midas.InputResolution.LARGE, // Use large resolution for better results
                encode: false,
            });

            // Normalize and visualize the depth map on a canvas
            const [height, width] = prediction.shape;
            const depthTensor = prediction.squeeze();
            const min = await depthTensor.min().data();
            const max = await depthTensor.max().data();
            const range = max[0] - min[0];

            const canvas = document.createElement('canvas');
            canvas.width = width;
            canvas.height = height;
            const ctx = canvas.getContext('2d');
            const imageData = ctx.createImageData(width, height);
            const data = imageData.data;

            // Get depth data as an array
            const depthData = await depthTensor.data();

            for (let i = 0; i < width * height; i++) {
                // Normalize the depth value (0 to 1) and invert for visualization (dark=close, bright=far)
                const normalizedDepth = (depthData[i] - min[0]) / range;
                const invertedGray = Math.floor(255 * (1 - normalizedDepth)); // Invert for traditional depth map view

                data[i * 4] = invertedGray;     // R
                data[i * 4 + 1] = invertedGray; // G
                data[i * 4 + 2] = invertedGray; // B
                data[i * 4 + 3] = 255;          // A
            }

            // Display depth map
            document.getElementById('depth-map-container').innerHTML = '';
            canvas.style.maxWidth = '100%';
            canvas.style.height = 'auto';
            canvas.style.borderRadius = '0.5rem';
            document.getElementById('depth-map-container').appendChild(canvas);

            // Clean up Tensors
            prediction.dispose();
            depthTensor.dispose();

            return imageData;
        }

        /**
         * TRELLIS 3D AI: Mesh Generator
         * @param {ImageData} depthMap - The depth map ImageData.
         * @returns {THREE.BufferGeometry} - The generated 3D mesh geometry.
         */
        function generateMeshFromDepth(depthMap, img) {
            const width = depthMap.width;
            const height = depthMap.height;
            const depthData = depthMap.data;
            const colorData = img ? getImageData(img) : null;

            const geometry = new THREE.BufferGeometry();
            const vertices = [];
            const colors = [];
            const uvs = [];
            const indices = [];

            const scale = 5; // Scaling factor for the 3D model size
            const depthMultiplier = 0.5; // Controls the perceived depth/extrusion

            for (let y = 0; y < height; y++) {
                for (let x = 0; x < width; x++) {
                    const i = (y * width + x);
                    const depthValue = depthData[i * 4]; // We used R channel for grayscale depth
                    const normalizedDepth = depthValue / 255; // 0 (near) to 1 (far)

                    // Position: Use image coordinates (x, y) and depth (z)
                    const xPos = (x / width - 0.5) * scale;
                    const yPos = (0.5 - y / height) * scale; // Invert y-axis for 3D system
                    // Invert depth: closer objects should push out more (negative Z)
                    const zPos = -normalizedDepth * depthMultiplier; 

                    vertices.push(xPos, yPos, zPos);

                    // UVs for texture mapping (using the original image as a texture)
                    uvs.push(x / width, 1 - y / height);

                    // Colors (optional, for vertex color if no texture is used)
                    if (colorData) {
                        const r = colorData.data[i * 4] / 255;
                        const g = colorData.data[i * 4 + 1] / 255;
                        const b = colorData.data[i * 4 + 2] / 255;
                        colors.push(r, g, b);
                    }
                }
            }

            // Create faces (triangles)
            for (let y = 0; y < height - 1; y++) {
                for (let x = 0; x < width - 1; x++) {
                    const i = y * width + x;
                    const iRight = i + 1;
                    const iDown = i + width;
                    const iDiag = i + width + 1;

                    // Triangle 1: Top-Left, Top-Right, Bottom-Left
                    indices.push(i, iRight, iDown);
                    // Triangle 2: Top-Right, Bottom-Right, Bottom-Left
                    indices.push(iRight, iDiag, iDown);
                }
            }

            geometry.setIndex(indices);
            geometry.setAttribute('position', new THREE.Float32BufferAttribute(vertices, 3));
            geometry.setAttribute('uv', new THREE.Float32BufferAttribute(uvs, 2));

            geometry.computeVertexNormals(); // Recalculate normals for proper lighting
            geometry.computeBoundingSphere();

            return geometry;
        }

        /** Helper to get image data from an HTMLImageElement */
        function getImageData(img) {
            const canvas = document.createElement('canvas');
            canvas.width = img.width;
            canvas.height = img.height;
            const ctx = canvas.getContext('2d');
            ctx.drawImage(img, 0, 0);
            return ctx.getImageData(0, 0, img.width, img.height);
        }

        // --- Event Handlers (Defined in Global Scope - FIX for ReferenceError) ---

        /** Handles file selection and updates the image preview. */
        function handleImageSelect(event) {
            const file = event.target.files[0];
            if (!file) return;

            const reader = new FileReader();
            reader.onload = (e) => {
                selectedImageBase64 = e.target.result;
                const preview = document.getElementById('image-preview');
                const label = document.getElementById('upload-label');
                const generateBtn = document.getElementById('generate-btn');

                preview.src = selectedImageBase64;
                preview.classList.remove('hidden');
                label.textContent = file.name;

                // Reset outputs
                document.getElementById('depth-map-container').innerHTML = 'Depth map will appear here after generation.';
                clearMesh();
                document.getElementById('export-btn').disabled = true;

                // Enable generate button
                generateBtn.disabled = false;
                showToast("Image Selected", "Click 'Generate 3D Model' to start processing.", false);
            };
            reader.readAsDataURL(file);
        }

        /** Clears the mesh from the scene. */
        function clearMesh() {
            if (meshGroup) {
                while(meshGroup.children.length > 0){
                    meshGroup.remove(meshGroup.children[0]);
                }
                currentMesh = null;
            }
        }

        /** Main function to orchestrate depth estimation and 3D mesh generation. */
        async function handleGenerate() {
            if (!selectedImageBase64 || isProcessing) return;

            isProcessing = true;
            document.getElementById('generate-btn').disabled = true;
            document.getElementById('export-btn').disabled = true;
            document.getElementById('loading-spinner').classList.remove('hidden');
            document.getElementById('generate-text').innerHTML = 'Processing...';

            clearMesh();

            try {
                // 1. Load image
                const img = new Image();
                img.crossOrigin = "anonymous";
                img.src = selectedImageBase64;
                await new Promise((resolve) => { img.onload = resolve; });

                // 2. Estimate depth (TRELLIS 3D AI step)
                showToast("Processing image", "Estimating depth map...", false);
                const depthMap = await estimateDepth(img);

                // 3. Generate mesh (TRELLIS 3D AI step)
                showToast("Generating 3D model", "Creating mesh from depth data...", false);
                const generatedGeometry = generateMeshFromDepth(depthMap, img);
                currentMesh = generatedGeometry;

                // 4. Create THREE.js Mesh with texture
                const texture = new THREE.TextureLoader().load(selectedImageBase64);
                texture.colorSpace = THREE.SRGBColorSpace;
                const material = new THREE.MeshPhongMaterial({
                    map: texture,
                    side: THREE.DoubleSide
                });

                const mesh = new THREE.Mesh(generatedGeometry, material);
                meshGroup.add(mesh); // Add to the main group
                
                // Center and set rotation
                generatedGeometry.computeBoundingBox();
                const center = new THREE.Vector3();
                generatedGeometry.boundingBox.getCenter(center);
                meshGroup.position.sub(center); // Recenter the group/mesh
                meshGroup.rotation.set(0.1, 0, 0); // Initial slight rotation

                showToast("Success!", "3D model generated successfully", false);
            } catch (error) {
                console.error('Generation error:', error);
                showToast("Generation failed", error.message || "An unknown error occurred", true);
            } finally {
                isProcessing = false;
                document.getElementById('generate-btn').disabled = !selectedImageBase64;
                document.getElementById('export-btn').disabled = !currentMesh;
                document.getElementById('loading-spinner').classList.add('hidden');
                document.getElementById('generate-text').innerHTML = 'üì¶ Generate 3D Model';
            }
        }

        /** Exports the current mesh to an OBJ file. */
        function handleExport() {
            if (!currentMesh) {
                showToast("No model to export", "Please generate a 3D model first", true);
                return;
            }

            try {
                // Simple OBJ Export function
                const geometry = currentMesh;
                const positions = geometry.attributes.position.array;
                const uvs = geometry.attributes.uv.array;
                const indices = geometry.index.array;
                
                let objContent = 'o GeneratedMesh\n';
                
                // Vertices (v)
                for (let i = 0; i < positions.length; i += 3) {
                    objContent += \`v \${positions[i].toFixed(4)} \${positions[i + 1].toFixed(4)} \${positions[i + 2].toFixed(4)}\n\`;
                }

                // UVs (vt)
                for (let i = 0; i < uvs.length; i += 2) {
                    objContent += \`vt \${uvs[i].toFixed(4)} \${uvs[i + 1].toFixed(4)}\n\`;
                }

                // Faces (f)
                for (let i = 0; i < indices.length; i += 3) {
                    // OBJ indices are 1-based, so we add 1
                    const i1 = indices[i] + 1;
                    const i2 = indices[i + 1] + 1;
                    const i3 = indices[i + 2] + 1;
                    
                    // Format: f v1/vt1 v2/vt2 v3/vt3
                    objContent += \`f \${i1}/\${i1} \${i2}/\${i2} \${i3}/\${i3}\n\`;
                }
                
                // Download function
                const blob = new Blob([objContent], { type: 'text/plain' });
                const link = document.createElement('a');
                link.href = URL.createObjectURL(blob);
                link.download = '3d-model.obj';
                document.body.appendChild(link);
                link.click();
                document.body.removeChild(link);
                
                showToast("Export successful", "OBJ file downloaded", false);
            } catch (error) {
                console.error('Export error:', error);
                showToast("Export failed", "Failed to export the model", true);
            }
        }

        // --- Initialization ---

        // Only run the 3D viewer initialization after all HTML and scripts are loaded.
        window.onload = () => {
            if (typeof THREE !== 'undefined') {
                initViewer3D();
            } else {
                showToast("Error", "THREE.js library failed to load. Check your internet connection or CDN link.", true);
            }
        };
    </script>
</body>
</html>
